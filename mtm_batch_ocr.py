"""
MTM Batch OCR Processor
Medya Takip Merkezi iÃ§in birden fazla gazete sayfasÄ±nÄ± batch olarak okuyup 
her kelimenin pozisyonunu kaydeden sistem
"""

import os
import re
import json
import glob
from typing import List, Dict, Tuple, Optional
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

import torch
if torch.version.cuda == '11.8':
    os.environ["TRITON_PTXAS_PATH"] = "/usr/local/cuda-11.8/bin/ptxas"
os.environ['VLLM_USE_V1'] = '0'

from PIL import Image, ImageDraw
import numpy as np

from vllm import LLM, SamplingParams
from vllm.model_executor.models.registry import ModelRegistry

# Import local modules
from deepseek_vllm.deepseek_ocr import DeepseekOCRForCausalLM
from deepseek_vllm.process.ngram_norepeat import NoRepeatNGramLogitsProcessor
from deepseek_vllm.process.image_process import DeepseekOCRProcessor

ModelRegistry.register_model("DeepseekOCRForCausalLM", DeepseekOCRForCausalLM)


class MTMOCRProcessor:
    """Medya Takip Merkezi iÃ§in OCR iÅŸleyici"""
    
    def __init__(
        self,
        model_path: str = "deepseek-ai/DeepSeek-OCR",
        output_dir: str = "output",
        device: str = "0",
        max_concurrency: int = 50,
        crop_mode: bool = True
    ):
        """
        Args:
            model_path: DeepSeek-OCR model yolu
            output_dir: Ã‡Ä±ktÄ± klasÃ¶rÃ¼
            device: GPU device ID
            max_concurrency: Maksimum eÅŸzamanlÄ± iÅŸlem sayÄ±sÄ±
            crop_mode: Dinamik kÄ±rpma modu
        """
        os.environ["CUDA_VISIBLE_DEVICES"] = device
        
        self.model_path = model_path
        self.output_dir = output_dir
        self.crop_mode = crop_mode
        
        # Output dizinlerini oluÅŸtur
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'results'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'visualizations'), exist_ok=True)
        
        # LLM'i baÅŸlat
        print("\n" + "="*70)
        print("DEEPSEEK OCR MODEL YUKLENIYOR")
        print("="*70)
        print(f"Model: {model_path}")
        print(f"GPU Memory Kullanimi: 90%")
        print(f"Maksimum Eslesme: {max_concurrency}")
        print(f"\n[1/5] Model dosyalari indiriliyor...")
        print("      Ilk calistirmada: ~15GB model indirilecek (5-10 dakika)")
        print("      Sonraki calistirmalarda: Cache'den yuklenecek (30-60 saniye)")
        
        import time
        start_time = time.time()
        
        print(f"\n[2/5] vLLM engine baslatiliyor...")
        print("      Model agirliklari GPU'ya yukleniyor...")
        
        self.llm = LLM(
            model=model_path,
            hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
            block_size=256,
            enforce_eager=False,
            trust_remote_code=True,
            max_model_len=8192,
            swap_space=0,
            max_num_seqs=max_concurrency,
            tensor_parallel_size=1,
            gpu_memory_utilization=0.9,
        )
        
        elapsed = time.time() - start_time
        print(f"\n[3/5] Model GPU'ya yuklendi ({elapsed:.1f} saniye)")
        print("      Inference parametreleri ayarlaniyor...")
        
        # Sampling parametreleri
        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=40, 
                window_size=90, 
                whitelist_token_ids={128821, 128822}
            )
        ]
        
        self.sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=8192,
            logits_processors=logits_processors,
            skip_special_tokens=False,
        )
        
        print(f"[4/5] Image processor baslatiliyor...")
        self.processor = DeepseekOCRProcessor()
        
        total_time = time.time() - start_time
        print(f"[5/5] Tamamlandi - Toplam sure: {total_time:.1f} saniye")
        print("\n" + "="*70)
        print("MODEL HAZIR - OCR islemleri yapilabilir")
        print("="*70 + "\n")
    
    def extract_word_positions(
        self, 
        text: str, 
        image_width: int, 
        image_height: int
    ) -> List[Dict]:
        """
        OCR Ã§Ä±ktÄ±sÄ±ndan kelimelerin pozisyonlarÄ±nÄ± Ã§Ä±kart
        
        Args:
            text: OCR Ã§Ä±ktÄ± metni
            image_width: GÃ¶rsel geniÅŸliÄŸi
            image_height: GÃ¶rsel yÃ¼ksekliÄŸi
            
        Returns:
            Kelime pozisyon bilgileri listesi
        """
        word_positions = []
        
        # GROUNDING TAG OLMADAN: Modelin kendi formatÄ±nÄ± kontrol et
        # Bazen markdown format dÃ¶ndÃ¼rÃ¼r, bazen dÃ¼z metin
        
        # Format 1: <|ref|>text<|/ref|><|det|>coords<|/det|>
        pattern1 = r'<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>'
        matches1 = re.findall(pattern1, text, re.DOTALL)
        
        # Format 2: <|ref|>text<|/ref|><|box|>coords<|/box|>
        pattern2 = r'<\|ref\|>(.*?)<\|/ref\|><\|box\|>(.*?)<\|/box\|>'
        matches2 = re.findall(pattern2, text, re.DOTALL)
        
        # Hangisi daha fazla sonuÃ§ veriyorsa onu kullan
        if len(matches1) > 0:
            matches = matches1
            format_name = "det"
        elif len(matches2) > 0:
            matches = matches2
            format_name = "box"
        else:
            matches = []
            format_name = "none"
        
        print(f"[DEBUG] Format tespit: <|{format_name}|> - {len(matches)} eslesmeler bulundu")
        print(f"[DEBUG] Raw output ilk 1000 karakter:")
        print(f"{text[:1000]}")
        
        # EÄŸer grounding formatÄ± yoksa, dÃ¼z metin olarak parse et
        if format_name == "none":
            print(f"[WARNING] Grounding formatÄ± yok - Model markdown veya duz metin donduruyor")
            print(f"[INFO] Bu durumda koordinat bilgisi olmayacak")
            print(f"[INFO] Ama metin raw_ocr_output ve full_text'te olacak")
            # Bu durumda sadece metin var, koordinat yok
            return []
        
        for idx, (word_text, coordinates_str) in enumerate(matches):
            try:
                # KoordinatlarÄ± parse et
                coordinates = eval(coordinates_str)
                
                # Liste iÃ§inde liste varsa dÃ¼zleÅŸtir
                if isinstance(coordinates, list):
                    if len(coordinates) > 0 and isinstance(coordinates[0], list):
                        # [[x1,y1,x2,y2]] formatÄ±
                        bbox_list = coordinates
                    else:
                        # [x1,y1,x2,y2] formatÄ±
                        bbox_list = [coordinates]
                    
                    for bbox in bbox_list:
                        if len(bbox) >= 4:
                            x1, y1, x2, y2 = bbox[:4]
                            
                            # Normalize edilmiÅŸ koordinatlarÄ± (0-999) gerÃ§ek piksel koordinatlarÄ±na Ã§evir
                            pixel_x1 = int(x1 / 999 * image_width)
                            pixel_y1 = int(y1 / 999 * image_height)
                            pixel_x2 = int(x2 / 999 * image_width)
                            pixel_y2 = int(y2 / 999 * image_height)
                            
                            word_positions.append({
                                'text': word_text.strip(),
                                'bbox': {
                                    'x1': pixel_x1,
                                    'y1': pixel_y1,
                                    'x2': pixel_x2,
                                    'y2': pixel_y2,
                                    'width': pixel_x2 - pixel_x1,
                                    'height': pixel_y2 - pixel_y1
                                },
                                'normalized_bbox': {
                                    'x1': x1,
                                    'y1': y1,
                                    'x2': x2,
                                    'y2': y2
                                },
                                'index': idx
                            })
            except Exception as e:
                print(f"[WARNING] Koordinat parse hatasi: {e}")
                print(f"           Word: {word_text[:50] if word_text else 'N/A'}...")
                print(f"           Coordinates: {coordinates_str[:100] if coordinates_str else 'N/A'}...")
                continue
        
        print(f"[INFO] Toplam {len(word_positions)} kelime pozisyonu cikarildi")
        return word_positions
    
    def extract_text_only(self, text: str) -> str:
        """
        OCR Ã§Ä±ktÄ±sÄ±ndan sadece metni Ã§Ä±kart (pozisyon taglarÄ± olmadan)
        Ã‡oklu format desteÄŸi
        """
        # <|ref|> taglarÄ± iÃ§indeki metni Ã§Ä±kart
        pattern = r'<\|ref\|>(.*?)<\|/ref\|>'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if matches:
            # TÃ¼m ref iÃ§eriklerini birleÅŸtir, kelimeler arasÄ± boÅŸluk bÄ±rak
            clean_text = ' '.join(match.strip() for match in matches if match.strip())
            print(f"[DEBUG] Ref taglarÄ±ndan {len(matches)} kelime Ã§Ä±karÄ±ldÄ±")
        else:
            # Fallback: TÃ¼m Ã¶zel taglarÄ± temizle
            print(f"[WARNING] <|ref|> tagÄ± bulunamadÄ±, fallback temizlik yapÄ±lÄ±yor")
            clean_text = re.sub(r'<\|.*?\|>', '', text)
            clean_text = re.sub(r'\n\n+', '\n\n', clean_text)
            clean_text = re.sub(r' +', ' ', clean_text)
        
        result = clean_text.strip()
        print(f"[DEBUG] Temiz metin uzunluÄŸu: {len(result)} karakter")
        return result
    
    def visualize_word_positions(
        self,
        image_path: str,
        word_positions: List[Dict],
        output_path: str,
        show_text: bool = True,
        box_color: tuple = None,
        box_width: int = 2
    ) -> Image.Image:
        """
        JSON'dan alÄ±nan kelime pozisyonlarÄ±nÄ± gÃ¶rsel Ã¼zerinde gÃ¶ster
        DeepSeek'ten baÄŸÄ±msÄ±z, kendi kutu Ã§izme sistemimiz
        
        Args:
            image_path: Orijinal gÃ¶rsel yolu
            word_positions: JSON'dan gelen kelime pozisyonlarÄ±
            output_path: Ã‡Ä±ktÄ± dosya yolu
            show_text: Kutunun Ã¼stÃ¼nde metni gÃ¶ster
            box_color: Kutu rengi (None ise rastgele)
            box_width: Kutu Ã§izgi kalÄ±nlÄ±ÄŸÄ±
            
        Returns:
            Bounding box'lÄ± gÃ¶rsel
        """
        print(f"[INFO] Gorsel uzerine {len(word_positions)} kelime icin kutu ciziliyor...")
        
        # Orijinal gÃ¶rseli yÃ¼kle
        image = Image.open(image_path).convert('RGB')
        img_draw = image.copy()
        
        # Draw objesi oluÅŸtur
        draw = ImageDraw.Draw(img_draw, 'RGBA')
        
        # Font yÃ¼kle
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 12)
        except:
            font = ImageFont.load_default()
        
        # Her kelime iÃ§in kutu Ã§iz
        for idx, word_info in enumerate(word_positions):
            try:
                bbox = word_info['bbox']
                text = word_info.get('text', '')
                
                # Renk belirle
                if box_color:
                    color = box_color
                else:
                    # Her kelime iÃ§in farklÄ± renk (ama okunabilir)
                    hue = (idx * 137.5) % 360  # Golden angle
                    import colorsys
                    rgb = colorsys.hsv_to_rgb(hue/360, 0.7, 0.9)
                    color = tuple(int(c * 255) for c in rgb)
                
                # Koordinatlar
                x1, y1 = bbox['x1'], bbox['y1']
                x2, y2 = bbox['x2'], bbox['y2']
                
                # Kutuyu Ã§iz
                draw.rectangle([x1, y1, x2, y2], outline=color, width=box_width)
                
                # YarÄ± saydam dolgu
                overlay = Image.new('RGBA', img_draw.size, (0, 0, 0, 0))
                overlay_draw = ImageDraw.Draw(overlay)
                overlay_draw.rectangle([x1, y1, x2, y2], fill=color + (30,))
                img_draw = Image.alpha_composite(img_draw.convert('RGBA'), overlay).convert('RGB')
                
                # Metin gÃ¶ster
                if show_text and text:
                    # Metin iÃ§in arka plan
                    text_bbox = draw.textbbox((0, 0), text, font=font)
                    text_width = text_bbox[2] - text_bbox[0]
                    text_height = text_bbox[3] - text_bbox[1]
                    
                    # Metin pozisyonu (kutunun Ã¼stÃ¼nde)
                    text_x = x1
                    text_y = max(0, y1 - text_height - 2)
                    
                    # Arka plan Ã§iz
                    draw = ImageDraw.Draw(img_draw)
                    draw.rectangle(
                        [text_x, text_y, text_x + text_width + 4, text_y + text_height + 2],
                        fill=(255, 255, 255, 200)
                    )
                    
                    # Metni Ã§iz
                    draw.text((text_x + 2, text_y), text, fill=color, font=font)
                
            except Exception as e:
                print(f"[WARNING] Kutu cizim hatasi ({idx}): {e}")
                continue
        
        # Kaydet
        img_draw.save(output_path, quality=95)
        print(f"[SUCCESS] Gorsel kaydedildi: {output_path}")
        
        return img_draw
    
    def process_single_image(
        self,
        image_path: str,
        prompt: str = "<image>\nFree OCR.",
        use_word_location: bool = True
    ) -> Dict:
        """
        Tek bir gÃ¶rseli iÅŸle
        
        Args:
            image_path: GÃ¶rsel dosya yolu
            prompt: OCR prompt
            
        Returns:
            Ä°ÅŸlem sonucu bilgileri
        """
        try:
            image = Image.open(image_path).convert('RGB')
            image_width, image_height = image.size
            
            # Image processing
            cache_item = {
                "prompt": prompt,
                "multi_modal_data": {
                    "image": self.processor.tokenize_with_images(
                        images=[image],
                        bos=True,
                        eos=True,
                        cropping=self.crop_mode
                    )
                },
            }
            
            return {
                'cache_item': cache_item,
                'image': image,
                'image_path': image_path,
                'width': image_width,
                'height': image_height
            }
            
        except Exception as e:
            print(f"[ERROR] Gorsel isleme hatasi ({image_path}): {e}")
            return None
    
    def locate_words_in_image(
        self,
        image_path: str,
        words: List[str],
        batch_size: int = 10
    ) -> Dict[str, Dict]:
        """
        Her kelime iÃ§in locate prompt ile koordinat bul
        kaynak.md'deki rec mode: <image>\nLocate <|ref|>xxxx<|/ref|> in the image.
        """
        print(f"[INFO] {len(words)} kelimenin koordinatlari araniyor...")
        
        word_locations = {}
        image = Image.open(image_path).convert('RGB')
        image_width, image_height = image.size
        
        # Kelimeleri batch'lere bÃ¶l (her seferinde batch_size kelime)
        for i in range(0, len(words), batch_size):
            batch_words = words[i:i+batch_size]
            print(f"[INFO] Batch {i//batch_size + 1}/{(len(words) + batch_size - 1)//batch_size}: {len(batch_words)} kelime")
            
            for word in batch_words:
                try:
                    # Locate prompt (kaynak.md satÄ±r 35)
                    locate_prompt = f"<image>\nLocate <|ref|>{word}<|/ref|> in the image."
                    
                    # Process image with locate prompt
                    cache_item = {
                        "prompt": locate_prompt,
                        "multi_modal_data": {
                            "image": self.processor.tokenize_with_images(
                                images=[image],
                                bos=True,
                                eos=True,
                                cropping=self.crop_mode
                            )
                        },
                    }
                    
                    # Generate
                    output = self.llm.generate([cache_item], sampling_params=self.sampling_params)[0]
                    response = output.outputs[0].text
                    
                    # Parse koordinat
                    pattern = r'<\|det\|>(.*?)<\|/det\|>'
                    coords_match = re.search(pattern, response)
                    
                    if coords_match:
                        coords_str = coords_match.group(1)
                        coords = eval(coords_str)
                        
                        if isinstance(coords, list) and len(coords) > 0:
                            bbox = coords[0] if isinstance(coords[0], list) else coords
                            if len(bbox) >= 4:
                                x1 = int(bbox[0] / 999 * image_width)
                                y1 = int(bbox[1] / 999 * image_height)
                                x2 = int(bbox[2] / 999 * image_width)
                                y2 = int(bbox[3] / 999 * image_height)
                                
                                word_locations[word] = {
                                    'bbox': {
                                        'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2,
                                        'width': x2 - x1, 'height': y2 - y1
                                    }
                                }
                except Exception as e:
                    print(f"[WARNING] '{word}' kelimesi icin koordinat bulunamadi: {e}")
                    continue
        
        print(f"[SUCCESS] {len(word_locations)}/{len(words)} kelimenin koordinati bulundu")
        return word_locations
    
    def process_batch(
        self,
        image_paths: List[str],
        prompt: str = "<image>\nFree OCR.",
        num_workers: int = 32,
        progress_callback: Optional[callable] = None,
        use_word_location: bool = True
    ) -> List[Dict]:
        """
        Birden fazla gÃ¶rseli batch olarak iÅŸle
        
        Args:
            image_paths: GÃ¶rsel dosya yollarÄ± listesi
            prompt: OCR prompt
            num_workers: Paralel iÅŸlem sayÄ±sÄ±
            progress_callback: Progress gÃ¼ncellemesi iÃ§in callback fonksiyonu
            
        Returns:
            TÃ¼m gÃ¶rseller iÃ§in OCR sonuÃ§larÄ±
        """
        print(f"\n[INFO] {len(image_paths)} gazete sayfasi isleniyor...")
        
        if progress_callback:
            progress_callback(0, len(image_paths), "Gorseller hazirlaniyor")
        
        # GÃ¶rselleri paralel olarak hazÄ±rla
        print("[1/3] Gorseller hazirlaniyor...")
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            processed_images = list(
                executor.map(
                    lambda p: self.process_single_image(p, prompt),
                    image_paths
                )
            )
        
        # None deÄŸerleri filtrele
        processed_images = [img for img in processed_images if img is not None]
        
        if not processed_images:
            print("[ERROR] Islenecek gorsel bulunamadi!")
            return []
        
        print(f"[INFO] {len(processed_images)} gorsel hazir")
        
        # Batch inference
        print("[2/3] OCR islemi yapiliyor...")
        if progress_callback:
            progress_callback(0, len(processed_images), "OCR islemi yapiliyor")
            
        batch_inputs = [img['cache_item'] for img in processed_images]
        
        outputs_list = self.llm.generate(
            batch_inputs,
            sampling_params=self.sampling_params
        )
        
        # SonuÃ§larÄ± iÅŸle ve kaydet
        print("[3/3] Sonuclar kaydediliyor...")
        if progress_callback:
            progress_callback(0, len(processed_images), "Sonuclar kaydediliyor")
            
        results = []
        
        for idx, (output, img_data) in enumerate(zip(outputs_list, processed_images)):
            if progress_callback:
                progress_callback(idx + 1, len(processed_images), f"Sonuc kaydediliyor ({idx+1}/{len(processed_images)})")
            try:
                # OCR Ã§Ä±ktÄ±sÄ±
                ocr_text = output.outputs[0].text
                
                # Dosya adÄ±
                image_filename = Path(img_data['image_path']).stem
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # Kelime pozisyonlarÄ±nÄ± Ã§Ä±kart
                word_positions = self.extract_word_positions(
                    ocr_text,
                    img_data['width'],
                    img_data['height']
                )
                
                # Temiz metni Ã§Ä±kart
                clean_text = self.extract_text_only(ocr_text)
                
                print(f"[DEBUG] OCR output length: {len(ocr_text)} characters")
                print(f"[DEBUG] Word positions from grounding: {len(word_positions)}")
                print(f"[DEBUG] Clean text length: {len(clean_text)} characters")
                
                # YENI STRATEJI: Free OCR ile metin aldÄ±k, ÅŸimdi her kelime iÃ§in locate
                if use_word_location and len(word_positions) < 20:  # EÄŸer az kelime varsa (paragraf seviyesi)
                    print(f"[INFO] Grounding yetersiz ({len(word_positions)} item), LOCATE modu baslatiliyor...")
                    
                    # Metinden kelimeleri ayÄ±r - OKUNUS SIRASINA GORE
                    all_words = clean_text.split()
                    all_words = [w.strip('.,!?;:()[]{}\"\'') for w in all_words if len(w.strip('.,!?;:()[]{}\"\'')) > 0]
                    
                    # Benzersiz kelimeleri al AMA sÄ±rayÄ± koru
                    seen = set()
                    unique_words = []
                    for word in all_words:
                        if word not in seen:
                            seen.add(word)
                            unique_words.append(word)
                    
                    print(f"[INFO] {len(unique_words)} benzersiz kelime bulundu (toplam {len(all_words)} kelime)")
                    
                    # Her kelime iÃ§in koordinat bul - BATCH SIZE 20
                    word_locations = self.locate_words_in_image(img_data['image_path'], unique_words, batch_size=20)
                    
                    # word_positions array'ini oluÅŸtur - OKUNUS SIRASINA GORE
                    word_positions = []
                    for idx, word_text in enumerate(all_words):
                        if word_text in word_locations:
                            word_positions.append({
                                'text': word_text,
                                'bbox': word_locations[word_text]['bbox'],
                                'index': idx  # Okunus sÄ±rasÄ±na gÃ¶re index
                            })
                    
                    print(f"[SUCCESS] LOCATE ile {len(word_positions)} kelimenin koordinati alindi (okunus sirasinda)!")
                
                # JSON sonuÃ§
                result_data = {
                    'image_path': img_data['image_path'],
                    'image_filename': image_filename,
                    'timestamp': timestamp,
                    'image_size': {
                        'width': img_data['width'],
                        'height': img_data['height']
                    },
                    'word_count': len(word_positions),
                    'words': word_positions,
                    'full_text': clean_text,
                    'raw_ocr_output': ocr_text
                }
                
                # JSON dosyasÄ±nÄ± kaydet
                json_path = os.path.join(
                    self.output_dir,
                    'results',
                    f'{image_filename}_{timestamp}.json'
                )
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, ensure_ascii=False, indent=2)
                
                # TXT dosyasÄ± artÄ±k kaydedilmiyor - her ÅŸey JSON'da
                
                # GÃ¶rselleÅŸtirme - BÄ°Z Ã‡Ä°ZÄ°YORUZ (DeepSeek deÄŸil!)
                viz_path = os.path.join(
                    self.output_dir,
                    'visualizations',
                    f'{image_filename}_{timestamp}_boxes.jpg'
                )
                self.visualize_word_positions(
                    img_data['image_path'],  # Orijinal gÃ¶rsel yolu
                    word_positions,
                    viz_path,
                    show_text=True,  # Kelimeyi gÃ¶ster
                    box_width=2  # Ä°nce Ã§izgi
                )
                
                results.append(result_data)
                
                print(f"âœ… {image_filename}: {len(word_positions)} kelime bulundu")
                
            except Exception as e:
                print(f"âŒ SonuÃ§ kaydetme hatasÄ± ({img_data['image_path']}): {e}")
                continue
        
        print(f"\nğŸ‰ Ä°ÅŸlem tamamlandÄ±! {len(results)} gazete baÅŸarÄ±yla iÅŸlendi.")
        print(f"ğŸ“ SonuÃ§lar: {self.output_dir}/results/")
        print(f"ğŸ–¼ï¸  GÃ¶rselleÅŸtirmeler: {self.output_dir}/visualizations/")
        
        return results


def main():
    """Ana fonksiyon - CLI kullanÄ±mÄ± iÃ§in"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='MTM Batch OCR - Gazete sayfalarÄ±nÄ± toplu olarak OCR ile iÅŸle'
    )
    parser.add_argument(
        '--input',
        type=str,
        required=True,
        help='Girdi klasÃ¶rÃ¼ veya dosya pattern (Ã¶rn: ./gazeteler/*.jpg)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='./output',
        help='Ã‡Ä±ktÄ± klasÃ¶rÃ¼'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='deepseek-ai/DeepSeek-OCR',
        help='Model yolu'
    )
    parser.add_argument(
        '--device',
        type=str,
        default='0',
        help='GPU device ID'
    )
    parser.add_argument(
        '--concurrency',
        type=int,
        default=50,
        help='Maksimum eÅŸzamanlÄ± iÅŸlem sayÄ±sÄ±'
    )
    parser.add_argument(
        '--workers',
        type=int,
        default=32,
        help='Paralel iÅŸlem sayÄ±sÄ±'
    )
    parser.add_argument(
        '--no-crop',
        action='store_true',
        help='Dinamik kÄ±rpma modunu devre dÄ±ÅŸÄ± bÄ±rak'
    )
    
    args = parser.parse_args()
    
    # GÃ¶rsel dosyalarÄ±nÄ± bul
    if os.path.isdir(args.input):
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
        image_paths = []
        for ext in image_extensions:
            image_paths.extend(glob.glob(os.path.join(args.input, ext)))
    else:
        image_paths = glob.glob(args.input)
    
    if not image_paths:
        print(f"âŒ {args.input} konumunda gÃ¶rsel bulunamadÄ±!")
        return
    
    print(f"ğŸ“¸ {len(image_paths)} gÃ¶rsel bulundu")
    
    # Processor'Ä± baÅŸlat
    processor = MTMOCRProcessor(
        model_path=args.model,
        output_dir=args.output,
        device=args.device,
        max_concurrency=args.concurrency,
        crop_mode=not args.no_crop
    )
    
    # Batch iÅŸleme
    results = processor.process_batch(
        image_paths,
        num_workers=args.workers
    )
    
    # Ã–zet rapor
    if results:
        total_words = sum(r['word_count'] for r in results)
        print(f"\nğŸ“Š Ã–ZET RAPOR:")
        print(f"   - Ä°ÅŸlenen sayfa: {len(results)}")
        print(f"   - Toplam kelime: {total_words}")
        print(f"   - Ortalama kelime/sayfa: {total_words/len(results):.1f}")


if __name__ == "__main__":
    main()

