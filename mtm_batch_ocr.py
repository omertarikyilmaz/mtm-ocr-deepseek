"""
MTM Batch OCR Processor
Medya Takip Merkezi iÃ§in birden fazla gazete sayfasÄ±nÄ± batch olarak okuyup 
her kelimenin pozisyonunu kaydeden sistem
"""

import os
import re
import json
import glob
from typing import List, Dict, Tuple, Optional
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

import torch
if torch.version.cuda == '11.8':
    os.environ["TRITON_PTXAS_PATH"] = "/usr/local/cuda-11.8/bin/ptxas"
os.environ['VLLM_USE_V1'] = '0'

from PIL import Image, ImageDraw
import numpy as np

from vllm import LLM, SamplingParams
from vllm.model_executor.models.registry import ModelRegistry

# Import local modules
from deepseek_vllm.deepseek_ocr import DeepseekOCRForCausalLM
from deepseek_vllm.process.ngram_norepeat import NoRepeatNGramLogitsProcessor
from deepseek_vllm.process.image_process import DeepseekOCRProcessor

ModelRegistry.register_model("DeepseekOCRForCausalLM", DeepseekOCRForCausalLM)


class MTMOCRProcessor:
    """Medya Takip Merkezi iÃ§in OCR iÅŸleyici"""
    
    def __init__(
        self,
        model_path: str = "deepseek-ai/DeepSeek-OCR",
        output_dir: str = "output",
        device: str = "0",
        max_concurrency: int = 50,
        crop_mode: bool = True
    ):
        """
        Args:
            model_path: DeepSeek-OCR model yolu
            output_dir: Ã‡Ä±ktÄ± klasÃ¶rÃ¼
            device: GPU device ID
            max_concurrency: Maksimum eÅŸzamanlÄ± iÅŸlem sayÄ±sÄ±
            crop_mode: Dinamik kÄ±rpma modu
        """
        os.environ["CUDA_VISIBLE_DEVICES"] = device
        
        self.model_path = model_path
        self.output_dir = output_dir
        self.crop_mode = crop_mode
        
        # Output dizinlerini oluÅŸtur
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'results'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'visualizations'), exist_ok=True)
        
        # LLM'i baÅŸlat
        print("\n" + "="*70)
        print("DEEPSEEK OCR MODEL YUKLENIYOR")
        print("="*70)
        print(f"Model: {model_path}")
        print(f"GPU Memory Kullanimi: 90%")
        print(f"Maksimum Eslesme: {max_concurrency}")
        print(f"\n[1/5] Model dosyalari indiriliyor...")
        print("      Ilk calistirmada: ~15GB model indirilecek (5-10 dakika)")
        print("      Sonraki calistirmalarda: Cache'den yuklenecek (30-60 saniye)")
        
        import time
        start_time = time.time()
        
        print(f"\n[2/5] vLLM engine baslatiliyor...")
        print("      Model agirliklari GPU'ya yukleniyor...")
        
        self.llm = LLM(
            model=model_path,
            hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
            block_size=256,
            enforce_eager=False,
            trust_remote_code=True,
            max_model_len=8192,
            swap_space=0,
            max_num_seqs=max_concurrency,
            tensor_parallel_size=1,
            gpu_memory_utilization=0.9,
        )
        
        elapsed = time.time() - start_time
        print(f"\n[3/5] Model GPU'ya yuklendi ({elapsed:.1f} saniye)")
        print("      Inference parametreleri ayarlaniyor...")
        
        # Sampling parametreleri
        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=40, 
                window_size=90, 
                whitelist_token_ids={128821, 128822}
            )
        ]
        
        self.sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=8192,
            logits_processors=logits_processors,
            skip_special_tokens=False,
        )
        
        print(f"[4/5] Image processor baslatiliyor...")
        self.processor = DeepseekOCRProcessor()
        
        total_time = time.time() - start_time
        print(f"[5/5] Tamamlandi - Toplam sure: {total_time:.1f} saniye")
        print("\n" + "="*70)
        print("MODEL HAZIR - OCR islemleri yapilabilir")
        print("="*70 + "\n")
    
    def extract_word_positions(
        self, 
        text: str, 
        image_width: int, 
        image_height: int
    ) -> List[Dict]:
        """
        OCR Ã§Ä±ktÄ±sÄ±ndan kelimelerin pozisyonlarÄ±nÄ± Ã§Ä±kart
        
        Args:
            text: OCR Ã§Ä±ktÄ± metni
            image_width: GÃ¶rsel geniÅŸliÄŸi
            image_height: GÃ¶rsel yÃ¼ksekliÄŸi
            
        Returns:
            Kelime pozisyon bilgileri listesi
        """
        word_positions = []
        
        # GROUNDING TAG OLMADAN: Modelin kendi formatÄ±nÄ± kontrol et
        # Bazen markdown format dÃ¶ndÃ¼rÃ¼r, bazen dÃ¼z metin
        
        # Format 1: <|ref|>text<|/ref|><|det|>coords<|/det|>
        pattern1 = r'<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>'
        matches1 = re.findall(pattern1, text, re.DOTALL)
        
        # Format 2: <|ref|>text<|/ref|><|box|>coords<|/box|>
        pattern2 = r'<\|ref\|>(.*?)<\|/ref\|><\|box\|>(.*?)<\|/box\|>'
        matches2 = re.findall(pattern2, text, re.DOTALL)
        
        # Hangisi daha fazla sonuÃ§ veriyorsa onu kullan
        if len(matches1) > 0:
            matches = matches1
            format_name = "det"
        elif len(matches2) > 0:
            matches = matches2
            format_name = "box"
        else:
            matches = []
            format_name = "none"
        
        print(f"[DEBUG] Format tespit: <|{format_name}|> - {len(matches)} eslesmeler bulundu")
        print(f"[DEBUG] Raw output ilk 1000 karakter:")
        print(f"{text[:1000]}")
        
        # EÄŸer grounding formatÄ± yoksa, dÃ¼z metin olarak parse et
        if format_name == "none":
            print(f"[WARNING] Grounding formatÄ± yok - Model duz metin donduruyor")
            print(f"[INFO] Bu normal! Grounding tag olmadan OCR yaptik")
            print(f"[INFO] Koordinat bilgisi yok ama metin var")
            # Bu durumda sadece metin var, koordinat yok
            # KullanÄ±cÄ±ya raw_ocr_output'tan metin gÃ¶stereceÄŸiz
            return []
        
        for idx, (word_text, coordinates_str) in enumerate(matches):
            try:
                # KoordinatlarÄ± parse et
                coordinates = eval(coordinates_str)
                
                # Liste iÃ§inde liste varsa dÃ¼zleÅŸtir
                if isinstance(coordinates, list):
                    if len(coordinates) > 0 and isinstance(coordinates[0], list):
                        # [[x1,y1,x2,y2]] formatÄ±
                        bbox_list = coordinates
                    else:
                        # [x1,y1,x2,y2] formatÄ±
                        bbox_list = [coordinates]
                    
                    for bbox in bbox_list:
                        if len(bbox) >= 4:
                            x1, y1, x2, y2 = bbox[:4]
                            
                            # Normalize edilmiÅŸ koordinatlarÄ± (0-999) gerÃ§ek piksel koordinatlarÄ±na Ã§evir
                            pixel_x1 = int(x1 / 999 * image_width)
                            pixel_y1 = int(y1 / 999 * image_height)
                            pixel_x2 = int(x2 / 999 * image_width)
                            pixel_y2 = int(y2 / 999 * image_height)
                            
                            word_positions.append({
                                'text': word_text.strip(),
                                'bbox': {
                                    'x1': pixel_x1,
                                    'y1': pixel_y1,
                                    'x2': pixel_x2,
                                    'y2': pixel_y2,
                                    'width': pixel_x2 - pixel_x1,
                                    'height': pixel_y2 - pixel_y1
                                },
                                'normalized_bbox': {
                                    'x1': x1,
                                    'y1': y1,
                                    'x2': x2,
                                    'y2': y2
                                },
                                'index': idx
                            })
            except Exception as e:
                print(f"[WARNING] Koordinat parse hatasi: {e}")
                print(f"           Word: {word_text[:50] if word_text else 'N/A'}...")
                print(f"           Coordinates: {coordinates_str[:100] if coordinates_str else 'N/A'}...")
                continue
        
        print(f"[INFO] Toplam {len(word_positions)} kelime pozisyonu cikarildi")
        return word_positions
    
    def extract_text_only(self, text: str) -> str:
        """
        OCR Ã§Ä±ktÄ±sÄ±ndan sadece metni Ã§Ä±kart (pozisyon taglarÄ± olmadan)
        Ã‡oklu format desteÄŸi
        """
        # <|ref|> taglarÄ± iÃ§indeki metni Ã§Ä±kart
        pattern = r'<\|ref\|>(.*?)<\|/ref\|>'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if matches:
            # TÃ¼m ref iÃ§eriklerini birleÅŸtir, kelimeler arasÄ± boÅŸluk bÄ±rak
            clean_text = ' '.join(match.strip() for match in matches if match.strip())
            print(f"[DEBUG] Ref taglarÄ±ndan {len(matches)} kelime Ã§Ä±karÄ±ldÄ±")
        else:
            # Fallback: TÃ¼m Ã¶zel taglarÄ± temizle
            print(f"[WARNING] <|ref|> tagÄ± bulunamadÄ±, fallback temizlik yapÄ±lÄ±yor")
            clean_text = re.sub(r'<\|.*?\|>', '', text)
            clean_text = re.sub(r'\n\n+', '\n\n', clean_text)
            clean_text = re.sub(r' +', ' ', clean_text)
        
        result = clean_text.strip()
        print(f"[DEBUG] Temiz metin uzunluÄŸu: {len(result)} karakter")
        return result
    
    def visualize_word_positions(
        self,
        image: Image.Image,
        word_positions: List[Dict],
        output_path: str
    ) -> Image.Image:
        """
        Kelime pozisyonlarÄ±nÄ± gÃ¶rsel Ã¼zerine Ã§iz
        
        Args:
            image: Orijinal gÃ¶rsel
            word_positions: Kelime pozisyon bilgileri
            output_path: Ã‡Ä±ktÄ± dosya yolu
            
        Returns:
            Bounding box'lÄ± gÃ¶rsel
        """
        img_draw = image.copy()
        draw = ImageDraw.Draw(img_draw)
        
        # YarÄ± saydam overlay
        overlay = Image.new('RGBA', img_draw.size, (0, 0, 0, 0))
        draw2 = ImageDraw.Draw(overlay)
        
        for word_info in word_positions:
            try:
                bbox = word_info['bbox']
                text = word_info['text']
                
                # Rastgele renk
                color = (
                    np.random.randint(50, 200),
                    np.random.randint(50, 200),
                    np.random.randint(50, 200)
                )
                color_alpha = color + (30,)
                
                # Bounding box Ã§iz
                x1, y1, x2, y2 = bbox['x1'], bbox['y1'], bbox['x2'], bbox['y2']
                draw.rectangle([x1, y1, x2, y2], outline=color, width=2)
                draw2.rectangle([x1, y1, x2, y2], fill=color_alpha)
                
            except Exception as e:
                print(f"âš ï¸ Ã‡izim hatasÄ±: {e}")
                continue
        
        img_draw.paste(overlay, (0, 0), overlay)
        img_draw.save(output_path)
        
        return img_draw
    
    def process_single_image(
        self,
        image_path: str,
        prompt: str = "<image>\nRecognize and extract all text from the image, including Turkish characters."
    ) -> Dict:
        """
        Tek bir gÃ¶rseli iÅŸle
        
        Args:
            image_path: GÃ¶rsel dosya yolu
            prompt: OCR prompt
            
        Returns:
            Ä°ÅŸlem sonucu bilgileri
        """
        try:
            image = Image.open(image_path).convert('RGB')
            image_width, image_height = image.size
            
            # Image processing
            cache_item = {
                "prompt": prompt,
                "multi_modal_data": {
                    "image": self.processor.tokenize_with_images(
                        images=[image],
                        bos=True,
                        eos=True,
                        cropping=self.crop_mode
                    )
                },
            }
            
            return {
                'cache_item': cache_item,
                'image': image,
                'image_path': image_path,
                'width': image_width,
                'height': image_height
            }
            
        except Exception as e:
            print(f"[ERROR] Gorsel isleme hatasi ({image_path}): {e}")
            return None
    
    def process_batch(
        self,
        image_paths: List[str],
        prompt: str = "<image>\nRecognize and extract all text from the image, including Turkish characters.",
        num_workers: int = 32,
        progress_callback: Optional[callable] = None
    ) -> List[Dict]:
        """
        Birden fazla gÃ¶rseli batch olarak iÅŸle
        
        Args:
            image_paths: GÃ¶rsel dosya yollarÄ± listesi
            prompt: OCR prompt
            num_workers: Paralel iÅŸlem sayÄ±sÄ±
            progress_callback: Progress gÃ¼ncellemesi iÃ§in callback fonksiyonu
            
        Returns:
            TÃ¼m gÃ¶rseller iÃ§in OCR sonuÃ§larÄ±
        """
        print(f"\n[INFO] {len(image_paths)} gazete sayfasi isleniyor...")
        
        if progress_callback:
            progress_callback(0, len(image_paths), "Gorseller hazirlaniyor")
        
        # GÃ¶rselleri paralel olarak hazÄ±rla
        print("[1/3] Gorseller hazirlaniyor...")
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            processed_images = list(
                executor.map(
                    lambda p: self.process_single_image(p, prompt),
                    image_paths
                )
            )
        
        # None deÄŸerleri filtrele
        processed_images = [img for img in processed_images if img is not None]
        
        if not processed_images:
            print("[ERROR] Islenecek gorsel bulunamadi!")
            return []
        
        print(f"[INFO] {len(processed_images)} gorsel hazir")
        
        # Batch inference
        print("[2/3] OCR islemi yapiliyor...")
        if progress_callback:
            progress_callback(0, len(processed_images), "OCR islemi yapiliyor")
            
        batch_inputs = [img['cache_item'] for img in processed_images]
        
        outputs_list = self.llm.generate(
            batch_inputs,
            sampling_params=self.sampling_params
        )
        
        # SonuÃ§larÄ± iÅŸle ve kaydet
        print("[3/3] Sonuclar kaydediliyor...")
        if progress_callback:
            progress_callback(0, len(processed_images), "Sonuclar kaydediliyor")
            
        results = []
        
        for idx, (output, img_data) in enumerate(zip(outputs_list, processed_images)):
            if progress_callback:
                progress_callback(idx + 1, len(processed_images), f"Sonuc kaydediliyor ({idx+1}/{len(processed_images)})")
            try:
                # OCR Ã§Ä±ktÄ±sÄ±
                ocr_text = output.outputs[0].text
                
                # Dosya adÄ±
                image_filename = Path(img_data['image_path']).stem
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # Kelime pozisyonlarÄ±nÄ± Ã§Ä±kart
                word_positions = self.extract_word_positions(
                    ocr_text,
                    img_data['width'],
                    img_data['height']
                )
                
                # Temiz metni Ã§Ä±kart
                clean_text = self.extract_text_only(ocr_text)
                
                # Debug: OCR output uzunluÄŸunu kontrol et
                print(f"[DEBUG] OCR output length: {len(ocr_text)} characters")
                print(f"[DEBUG] Word positions: {len(word_positions)}")
                print(f"[DEBUG] Clean text length: {len(clean_text)} characters")
                
                # JSON sonuÃ§
                result_data = {
                    'image_path': img_data['image_path'],
                    'image_filename': image_filename,
                    'timestamp': timestamp,
                    'image_size': {
                        'width': img_data['width'],
                        'height': img_data['height']
                    },
                    'word_count': len(word_positions),
                    'words': word_positions,
                    'full_text': clean_text,
                    'raw_ocr_output': ocr_text
                }
                
                # JSON dosyasÄ±nÄ± kaydet
                json_path = os.path.join(
                    self.output_dir,
                    'results',
                    f'{image_filename}_{timestamp}.json'
                )
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, ensure_ascii=False, indent=2)
                
                # TXT dosyasÄ± artÄ±k kaydedilmiyor - her ÅŸey JSON'da
                
                # GÃ¶rselleÅŸtirme
                viz_path = os.path.join(
                    self.output_dir,
                    'visualizations',
                    f'{image_filename}_{timestamp}_boxes.jpg'
                )
                self.visualize_word_positions(
                    img_data['image'],
                    word_positions,
                    viz_path
                )
                
                results.append(result_data)
                
                print(f"âœ… {image_filename}: {len(word_positions)} kelime bulundu")
                
            except Exception as e:
                print(f"âŒ SonuÃ§ kaydetme hatasÄ± ({img_data['image_path']}): {e}")
                continue
        
        print(f"\nğŸ‰ Ä°ÅŸlem tamamlandÄ±! {len(results)} gazete baÅŸarÄ±yla iÅŸlendi.")
        print(f"ğŸ“ SonuÃ§lar: {self.output_dir}/results/")
        print(f"ğŸ–¼ï¸  GÃ¶rselleÅŸtirmeler: {self.output_dir}/visualizations/")
        
        return results


def main():
    """Ana fonksiyon - CLI kullanÄ±mÄ± iÃ§in"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='MTM Batch OCR - Gazete sayfalarÄ±nÄ± toplu olarak OCR ile iÅŸle'
    )
    parser.add_argument(
        '--input',
        type=str,
        required=True,
        help='Girdi klasÃ¶rÃ¼ veya dosya pattern (Ã¶rn: ./gazeteler/*.jpg)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='./output',
        help='Ã‡Ä±ktÄ± klasÃ¶rÃ¼'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='deepseek-ai/DeepSeek-OCR',
        help='Model yolu'
    )
    parser.add_argument(
        '--device',
        type=str,
        default='0',
        help='GPU device ID'
    )
    parser.add_argument(
        '--concurrency',
        type=int,
        default=50,
        help='Maksimum eÅŸzamanlÄ± iÅŸlem sayÄ±sÄ±'
    )
    parser.add_argument(
        '--workers',
        type=int,
        default=32,
        help='Paralel iÅŸlem sayÄ±sÄ±'
    )
    parser.add_argument(
        '--no-crop',
        action='store_true',
        help='Dinamik kÄ±rpma modunu devre dÄ±ÅŸÄ± bÄ±rak'
    )
    
    args = parser.parse_args()
    
    # GÃ¶rsel dosyalarÄ±nÄ± bul
    if os.path.isdir(args.input):
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
        image_paths = []
        for ext in image_extensions:
            image_paths.extend(glob.glob(os.path.join(args.input, ext)))
    else:
        image_paths = glob.glob(args.input)
    
    if not image_paths:
        print(f"âŒ {args.input} konumunda gÃ¶rsel bulunamadÄ±!")
        return
    
    print(f"ğŸ“¸ {len(image_paths)} gÃ¶rsel bulundu")
    
    # Processor'Ä± baÅŸlat
    processor = MTMOCRProcessor(
        model_path=args.model,
        output_dir=args.output,
        device=args.device,
        max_concurrency=args.concurrency,
        crop_mode=not args.no_crop
    )
    
    # Batch iÅŸleme
    results = processor.process_batch(
        image_paths,
        num_workers=args.workers
    )
    
    # Ã–zet rapor
    if results:
        total_words = sum(r['word_count'] for r in results)
        print(f"\nğŸ“Š Ã–ZET RAPOR:")
        print(f"   - Ä°ÅŸlenen sayfa: {len(results)}")
        print(f"   - Toplam kelime: {total_words}")
        print(f"   - Ortalama kelime/sayfa: {total_words/len(results):.1f}")


if __name__ == "__main__":
    main()

