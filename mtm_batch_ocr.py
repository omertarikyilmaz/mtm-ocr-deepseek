"""
MTM Batch OCR Processor
Medya Takip Merkezi iÃ§in birden fazla gazete sayfasÄ±nÄ± batch olarak okuyup 
her kelimenin pozisyonunu kaydeden sistem
"""

import os
import re
import json
import glob
from typing import List, Dict, Tuple, Optional
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

import torch
if torch.version.cuda == '11.8':
    os.environ["TRITON_PTXAS_PATH"] = "/usr/local/cuda-11.8/bin/ptxas"
os.environ['VLLM_USE_V1'] = '0'

from PIL import Image, ImageDraw
import numpy as np

from vllm import LLM, SamplingParams
from vllm.model_executor.models.registry import ModelRegistry

# Import local modules
from deepseek_vllm.deepseek_ocr import DeepseekOCRForCausalLM
from deepseek_vllm.process.ngram_norepeat import NoRepeatNGramLogitsProcessor
from deepseek_vllm.process.image_process import DeepseekOCRProcessor

ModelRegistry.register_model("DeepseekOCRForCausalLM", DeepseekOCRForCausalLM)


class MTMOCRProcessor:
    """Medya Takip Merkezi iÃ§in OCR iÅŸleyici"""
    
    def __init__(
        self,
        model_path: str = "deepseek-ai/DeepSeek-OCR",
        output_dir: str = "output",
        device: str = "0",
        max_concurrency: int = 50,
        crop_mode: bool = True
    ):
        """
        Args:
            model_path: DeepSeek-OCR model yolu
            output_dir: Ã‡Ä±ktÄ± klasÃ¶rÃ¼
            device: GPU device ID
            max_concurrency: Maksimum eÅŸzamanlÄ± iÅŸlem sayÄ±sÄ±
            crop_mode: Dinamik kÄ±rpma modu
        """
        os.environ["CUDA_VISIBLE_DEVICES"] = device
        
        self.model_path = model_path
        self.output_dir = output_dir
        self.crop_mode = crop_mode
        
        # Output dizinlerini oluÅŸtur
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'results'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'visualizations'), exist_ok=True)
        
        # LLM'i baÅŸlat
        print("\n" + "="*70)
        print("ğŸš€ DEEPSEEK OCR MODEL YÃœKLENÄ°YOR...")
        print("="*70)
        print(f"ğŸ“¦ Model: {model_path}")
        print(f"ğŸ’¾ GPU Memory: 90% kullanÄ±lacak")
        print(f"âš¡ Max Concurrent: {max_concurrency}")
        print("\nğŸ“¥ Model dosyalarÄ± indiriliyor/yÃ¼kleniyor...")
        print("   (Ä°lk Ã§alÄ±ÅŸtÄ±rmada ~15GB model indirilecek, 5-10 dakika sÃ¼rebilir)")
        print("   (Sonraki Ã§alÄ±ÅŸtÄ±rmalarda cache'den yÃ¼klenecek, 30-60 saniye)\n")
        
        self.llm = LLM(
            model=model_path,
            hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
            block_size=256,
            enforce_eager=False,
            trust_remote_code=True,
            max_model_len=8192,
            swap_space=0,
            max_num_seqs=max_concurrency,
            tensor_parallel_size=1,
            gpu_memory_utilization=0.9,
        )
        
        print("\nğŸ”§ Model GPU'ya yÃ¼klendi, parametreler ayarlanÄ±yor...")
        
        # Sampling parametreleri
        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=40, 
                window_size=90, 
                whitelist_token_ids={128821, 128822}
            )
        ]
        
        self.sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=8192,
            logits_processors=logits_processors,
            skip_special_tokens=False,
        )
        
        print("ğŸ–¼ï¸  Image processor hazÄ±rlanÄ±yor...")
        self.processor = DeepseekOCRProcessor()
        
        print("\n" + "="*70)
        print("âœ… MODEL TAMAMEN HAZIR! OCR iÅŸlemleri yapÄ±labilir.")
        print("="*70 + "\n")
    
    def extract_word_positions(
        self, 
        text: str, 
        image_width: int, 
        image_height: int
    ) -> List[Dict]:
        """
        OCR Ã§Ä±ktÄ±sÄ±ndan kelimelerin pozisyonlarÄ±nÄ± Ã§Ä±kart
        
        Args:
            text: OCR Ã§Ä±ktÄ± metni
            image_width: GÃ¶rsel geniÅŸliÄŸi
            image_height: GÃ¶rsel yÃ¼ksekliÄŸi
            
        Returns:
            Kelime pozisyon bilgileri listesi
        """
        # <|ref|>text<|/ref|><|det|>[[x1,y1,x2,y2]]<|/det|> formatÄ±nÄ± bul
        pattern = r'<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>'
        matches = re.findall(pattern, text, re.DOTALL)
        
        word_positions = []
        
        for idx, (word_text, coordinates_str) in enumerate(matches):
            try:
                # KoordinatlarÄ± parse et
                coordinates = eval(coordinates_str)
                
                # Her bbox iÃ§in kelime bilgisi kaydet
                for bbox in coordinates:
                    if len(bbox) >= 4:
                        x1, y1, x2, y2 = bbox[:4]
                        
                        # Normalize edilmiÅŸ koordinatlarÄ± (0-999) gerÃ§ek piksel koordinatlarÄ±na Ã§evir
                        pixel_x1 = int(x1 / 999 * image_width)
                        pixel_y1 = int(y1 / 999 * image_height)
                        pixel_x2 = int(x2 / 999 * image_width)
                        pixel_y2 = int(y2 / 999 * image_height)
                        
                        word_positions.append({
                            'text': word_text.strip(),
                            'bbox': {
                                'x1': pixel_x1,
                                'y1': pixel_y1,
                                'x2': pixel_x2,
                                'y2': pixel_y2,
                                'width': pixel_x2 - pixel_x1,
                                'height': pixel_y2 - pixel_y1
                            },
                            'normalized_bbox': {
                                'x1': x1,
                                'y1': y1,
                                'x2': x2,
                                'y2': y2
                            },
                            'index': idx
                        })
            except Exception as e:
                print(f"âš ï¸ Koordinat parse hatasÄ±: {e}")
                continue
        
        return word_positions
    
    def extract_text_only(self, text: str) -> str:
        """
        OCR Ã§Ä±ktÄ±sÄ±ndan sadece metni Ã§Ä±kart (pozisyon taglarÄ± olmadan)
        
        Args:
            text: OCR Ã§Ä±ktÄ± metni
            
        Returns:
            Temiz metin
        """
        # TÃ¼m ref ve det taglarÄ±nÄ± temizle
        pattern = r'<\|ref\|>.*?<\|/ref\|><\|det\|>.*?<\|/det\|>'
        clean_text = re.sub(pattern, '', text, flags=re.DOTALL)
        
        # Fazla boÅŸluklarÄ± temizle
        clean_text = re.sub(r'\n\n+', '\n\n', clean_text)
        clean_text = re.sub(r' +', ' ', clean_text)
        
        return clean_text.strip()
    
    def visualize_word_positions(
        self,
        image: Image.Image,
        word_positions: List[Dict],
        output_path: str
    ) -> Image.Image:
        """
        Kelime pozisyonlarÄ±nÄ± gÃ¶rsel Ã¼zerine Ã§iz
        
        Args:
            image: Orijinal gÃ¶rsel
            word_positions: Kelime pozisyon bilgileri
            output_path: Ã‡Ä±ktÄ± dosya yolu
            
        Returns:
            Bounding box'lÄ± gÃ¶rsel
        """
        img_draw = image.copy()
        draw = ImageDraw.Draw(img_draw)
        
        # YarÄ± saydam overlay
        overlay = Image.new('RGBA', img_draw.size, (0, 0, 0, 0))
        draw2 = ImageDraw.Draw(overlay)
        
        for word_info in word_positions:
            try:
                bbox = word_info['bbox']
                text = word_info['text']
                
                # Rastgele renk
                color = (
                    np.random.randint(50, 200),
                    np.random.randint(50, 200),
                    np.random.randint(50, 200)
                )
                color_alpha = color + (30,)
                
                # Bounding box Ã§iz
                x1, y1, x2, y2 = bbox['x1'], bbox['y1'], bbox['x2'], bbox['y2']
                draw.rectangle([x1, y1, x2, y2], outline=color, width=2)
                draw2.rectangle([x1, y1, x2, y2], fill=color_alpha)
                
            except Exception as e:
                print(f"âš ï¸ Ã‡izim hatasÄ±: {e}")
                continue
        
        img_draw.paste(overlay, (0, 0), overlay)
        img_draw.save(output_path)
        
        return img_draw
    
    def process_single_image(
        self,
        image_path: str,
        prompt: str = "<image>\n<|grounding|>Convert the document to markdown."
    ) -> Dict:
        """
        Tek bir gÃ¶rseli iÅŸle
        
        Args:
            image_path: GÃ¶rsel dosya yolu
            prompt: OCR prompt
            
        Returns:
            Ä°ÅŸlem sonucu bilgileri
        """
        try:
            image = Image.open(image_path).convert('RGB')
            image_width, image_height = image.size
            
            # Image processing
            cache_item = {
                "prompt": prompt,
                "multi_modal_data": {
                    "image": self.processor.tokenize_with_images(
                        images=[image],
                        bos=True,
                        eos=True,
                        cropping=self.crop_mode
                    )
                },
            }
            
            return {
                'cache_item': cache_item,
                'image': image,
                'image_path': image_path,
                'width': image_width,
                'height': image_height
            }
            
        except Exception as e:
            print(f"âŒ GÃ¶rsel iÅŸleme hatasÄ± ({image_path}): {e}")
            return None
    
    def process_batch(
        self,
        image_paths: List[str],
        prompt: str = "<image>\n<|grounding|>Convert the document to markdown.",
        num_workers: int = 32,
        progress_callback: Optional[callable] = None
    ) -> List[Dict]:
        """
        Birden fazla gÃ¶rseli batch olarak iÅŸle
        
        Args:
            image_paths: GÃ¶rsel dosya yollarÄ± listesi
            prompt: OCR prompt
            num_workers: Paralel iÅŸlem sayÄ±sÄ±
            progress_callback: Progress gÃ¼ncellemesi iÃ§in callback fonksiyonu
            
        Returns:
            TÃ¼m gÃ¶rseller iÃ§in OCR sonuÃ§larÄ±
        """
        print(f"\nğŸ“° {len(image_paths)} gazete sayfasÄ± iÅŸleniyor...")
        
        if progress_callback:
            progress_callback(0, len(image_paths), "GÃ¶rseller hazÄ±rlanÄ±yor...")
        
        # GÃ¶rselleri paralel olarak hazÄ±rla
        print("ğŸ”„ GÃ¶rseller hazÄ±rlanÄ±yor...")
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            processed_images = list(
                executor.map(
                    lambda p: self.process_single_image(p, prompt),
                    image_paths
                )
            )
        
        # None deÄŸerleri filtrele
        processed_images = [img for img in processed_images if img is not None]
        
        if not processed_images:
            print("âŒ Ä°ÅŸlenecek gÃ¶rsel bulunamadÄ±!")
            return []
        
        # Batch inference
        print("ğŸ¤– OCR iÅŸlemi yapÄ±lÄ±yor...")
        if progress_callback:
            progress_callback(0, len(processed_images), "OCR iÅŸlemi yapÄ±lÄ±yor...")
            
        batch_inputs = [img['cache_item'] for img in processed_images]
        
        outputs_list = self.llm.generate(
            batch_inputs,
            sampling_params=self.sampling_params
        )
        
        # SonuÃ§larÄ± iÅŸle ve kaydet
        print("ğŸ’¾ SonuÃ§lar kaydediliyor...")
        if progress_callback:
            progress_callback(0, len(processed_images), "SonuÃ§lar kaydediliyor...")
            
        results = []
        
        for idx, (output, img_data) in enumerate(zip(outputs_list, processed_images)):
            if progress_callback:
                progress_callback(idx + 1, len(processed_images), f"SonuÃ§ kaydediliyor... ({idx+1}/{len(processed_images)})")
            try:
                # OCR Ã§Ä±ktÄ±sÄ±
                ocr_text = output.outputs[0].text
                
                # Dosya adÄ±
                image_filename = Path(img_data['image_path']).stem
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # Kelime pozisyonlarÄ±nÄ± Ã§Ä±kart
                word_positions = self.extract_word_positions(
                    ocr_text,
                    img_data['width'],
                    img_data['height']
                )
                
                # Temiz metni Ã§Ä±kart
                clean_text = self.extract_text_only(ocr_text)
                
                # JSON sonuÃ§
                result_data = {
                    'image_path': img_data['image_path'],
                    'image_filename': image_filename,
                    'timestamp': timestamp,
                    'image_size': {
                        'width': img_data['width'],
                        'height': img_data['height']
                    },
                    'word_count': len(word_positions),
                    'words': word_positions,
                    'full_text': clean_text,
                    'raw_ocr_output': ocr_text
                }
                
                # JSON dosyasÄ±nÄ± kaydet
                json_path = os.path.join(
                    self.output_dir,
                    'results',
                    f'{image_filename}_{timestamp}.json'
                )
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, ensure_ascii=False, indent=2)
                
                # Temiz metni kaydet
                text_path = os.path.join(
                    self.output_dir,
                    'results',
                    f'{image_filename}_{timestamp}.txt'
                )
                with open(text_path, 'w', encoding='utf-8') as f:
                    f.write(clean_text)
                
                # GÃ¶rselleÅŸtirme
                viz_path = os.path.join(
                    self.output_dir,
                    'visualizations',
                    f'{image_filename}_{timestamp}_boxes.jpg'
                )
                self.visualize_word_positions(
                    img_data['image'],
                    word_positions,
                    viz_path
                )
                
                results.append(result_data)
                
                print(f"âœ… {image_filename}: {len(word_positions)} kelime bulundu")
                
            except Exception as e:
                print(f"âŒ SonuÃ§ kaydetme hatasÄ± ({img_data['image_path']}): {e}")
                continue
        
        print(f"\nğŸ‰ Ä°ÅŸlem tamamlandÄ±! {len(results)} gazete baÅŸarÄ±yla iÅŸlendi.")
        print(f"ğŸ“ SonuÃ§lar: {self.output_dir}/results/")
        print(f"ğŸ–¼ï¸  GÃ¶rselleÅŸtirmeler: {self.output_dir}/visualizations/")
        
        return results


def main():
    """Ana fonksiyon - CLI kullanÄ±mÄ± iÃ§in"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='MTM Batch OCR - Gazete sayfalarÄ±nÄ± toplu olarak OCR ile iÅŸle'
    )
    parser.add_argument(
        '--input',
        type=str,
        required=True,
        help='Girdi klasÃ¶rÃ¼ veya dosya pattern (Ã¶rn: ./gazeteler/*.jpg)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='./output',
        help='Ã‡Ä±ktÄ± klasÃ¶rÃ¼'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='deepseek-ai/DeepSeek-OCR',
        help='Model yolu'
    )
    parser.add_argument(
        '--device',
        type=str,
        default='0',
        help='GPU device ID'
    )
    parser.add_argument(
        '--concurrency',
        type=int,
        default=50,
        help='Maksimum eÅŸzamanlÄ± iÅŸlem sayÄ±sÄ±'
    )
    parser.add_argument(
        '--workers',
        type=int,
        default=32,
        help='Paralel iÅŸlem sayÄ±sÄ±'
    )
    parser.add_argument(
        '--no-crop',
        action='store_true',
        help='Dinamik kÄ±rpma modunu devre dÄ±ÅŸÄ± bÄ±rak'
    )
    
    args = parser.parse_args()
    
    # GÃ¶rsel dosyalarÄ±nÄ± bul
    if os.path.isdir(args.input):
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
        image_paths = []
        for ext in image_extensions:
            image_paths.extend(glob.glob(os.path.join(args.input, ext)))
    else:
        image_paths = glob.glob(args.input)
    
    if not image_paths:
        print(f"âŒ {args.input} konumunda gÃ¶rsel bulunamadÄ±!")
        return
    
    print(f"ğŸ“¸ {len(image_paths)} gÃ¶rsel bulundu")
    
    # Processor'Ä± baÅŸlat
    processor = MTMOCRProcessor(
        model_path=args.model,
        output_dir=args.output,
        device=args.device,
        max_concurrency=args.concurrency,
        crop_mode=not args.no_crop
    )
    
    # Batch iÅŸleme
    results = processor.process_batch(
        image_paths,
        num_workers=args.workers
    )
    
    # Ã–zet rapor
    if results:
        total_words = sum(r['word_count'] for r in results)
        print(f"\nğŸ“Š Ã–ZET RAPOR:")
        print(f"   - Ä°ÅŸlenen sayfa: {len(results)}")
        print(f"   - Toplam kelime: {total_words}")
        print(f"   - Ortalama kelime/sayfa: {total_words/len(results):.1f}")


if __name__ == "__main__":
    main()

