# ðŸ”§ Docker Build HatasÄ± Ã‡Ã¶zÃ¼mÃ¼

## âŒ Hata

```
ERROR: Could not find a version that satisfies the requirement vllm==0.8.5+cu118
```

## âœ… Ã‡Ã¶zÃ¼m

### Problem Analizi

1. **vLLM 0.8.5+cu118** versiyonu artÄ±k PyPI'da mevcut deÄŸil
2. vLLM artÄ±k CUDA versiyonlarÄ±nÄ± farklÄ± ÅŸekilde daÄŸÄ±tÄ±yor
3. CUDA 11.8 desteÄŸi eskimiÅŸ durumda

### Uygulanan Ã‡Ã¶zÃ¼m

**CUDA ve PyTorch versiyonlarÄ± gÃ¼ncellendi:**

| Ã–nceki (HatalÄ±) | Yeni (Ã‡alÄ±ÅŸan) |
|-----------------|----------------|
| CUDA 11.8 | **CUDA 12.1** |
| PyTorch 2.6.0 | **PyTorch 2.4.0** |
| vllm==0.8.5+cu118 | **vllm==0.8.5** |
| flash-attn 2.7.3 | **flash-attn 2.7.2.post1** |

### DeÄŸiÅŸen Dosyalar

1. âœ… `Dockerfile` - CUDA 12.1 base image
2. âœ… `requirements.txt` - GÃ¼ncel versiyonlar
3. âœ… `docker-entrypoint.sh` - CUDA versiyon bilgisi
4. âœ… `README.md` - Kurulum talimatlarÄ±

## ðŸš€ NasÄ±l KullanÄ±lÄ±r

### 1. En Son DeÄŸiÅŸiklikleri Ã‡ek (sunucunuzda)

```bash
cd /home/omer/projects/mtm-ocr-deepseek

# Eski build cache'ini temizle
docker-compose down
docker system prune -af

# En son kodu Ã§ek
git pull origin main
```

### 2. Yeniden Build Et

```bash
# Build et
docker-compose build --no-cache

# BaÅŸlat
docker-compose up -d

# LoglarÄ± izle
docker-compose logs -f
```

### 3. Manuel Build (detaylÄ± log iÃ§in)

```bash
# AdÄ±m adÄ±m build
docker build -t mtm-ocr:latest -f Dockerfile .

# Manuel baÅŸlat
docker run --runtime=nvidia --gpus all \
  -p 5000:5000 \
  -v $(pwd)/output:/app/output \
  -v $(pwd)/uploads:/app/uploads \
  mtm-ocr:latest
```

## ðŸ” Sorun Giderme

### GPU Kontrol

```bash
# Container iÃ§inde GPU eriÅŸimi test et
docker run --rm --gpus all nvidia/cuda:12.1.0-base nvidia-smi
```

### Driver KontrolÃ¼

```bash
# NVIDIA driver versiyonu (>= 530.30.02 olmalÄ±)
nvidia-smi

# CUDA versiyonu
nvcc --version
```

### Build LoglarÄ±nÄ± Kaydet

```bash
docker-compose build --no-cache 2>&1 | tee build.log
```

## ðŸ“‹ Gereksinimler

### Sistem Gereksinimleri

- **NVIDIA Driver**: >= 530.30.02
- **Docker**: >= 20.10
- **docker-compose**: >= 1.29
- **nvidia-docker2**: Kurulu olmalÄ±

### GPU Gereksinimleri

- **Minimum**: 16GB VRAM (GTX 1080 Ti, RTX 3060 12GB)
- **Ã–nerilen**: 24GB+ VRAM (RTX 3090, RTX 4090, A100)

## âš™ï¸ Alternatif Ã‡Ã¶zÃ¼mler

### Ã‡Ã¶zÃ¼m 1: CUDA 11.8 ile Devam (Ã–nerilmez)

EÄŸer mutlaka CUDA 11.8 kullanmanÄ±z gerekiyorsa:

```dockerfile
# Dockerfile iÃ§inde
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04

# PyTorch
RUN pip3 install torch==2.4.0 torchvision==0.19.0 \
    --index-url https://download.pytorch.org/whl/cu118

# vLLM (CUDA tag olmadan)
RUN pip3 install vllm==0.8.5
```

### Ã‡Ã¶zÃ¼m 2: En Yeni Versiyonlar (Ä°leri DÃ¼zey)

```dockerfile
FROM nvidia/cuda:12.4.0-cudnn9-devel-ubuntu22.04

RUN pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu124
RUN pip3 install vllm
```

## ðŸ“ Test AdÄ±mlarÄ±

### 1. Build Testi

```bash
docker-compose build
# âœ… HatasÄ±z tamamlanmalÄ±
```

### 2. Container BaÅŸlatma Testi

```bash
docker-compose up -d
docker-compose logs -f
# âœ… "Model hazÄ±r!" mesajÄ±nÄ± gÃ¶rmelisiniz
```

### 3. GPU EriÅŸim Testi

```bash
docker-compose exec mtm-ocr python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else None}')"
# âœ… CUDA: True gÃ¶rmelisiniz
```

### 4. Web UI Testi

```bash
curl http://localhost:5000
# âœ… HTML iÃ§eriÄŸi dÃ¶nmeli
```

## ðŸŽ¯ SonuÃ§

**YapÄ±lan DeÄŸiÅŸiklikler:**
- âœ… CUDA 11.8 â†’ CUDA 12.1
- âœ… PyTorch 2.6.0 â†’ PyTorch 2.4.0
- âœ… vllm==0.8.5+cu118 â†’ vllm==0.8.5
- âœ… TÃ¼m baÄŸÄ±mlÄ±lÄ±klar uyumlu hale getirildi

**Beklenen SonuÃ§:**
- âœ… Docker build hatasÄ±z tamamlanÄ±r
- âœ… Container baÅŸarÄ±yla baÅŸlar
- âœ… GPU eriÅŸimi Ã§alÄ±ÅŸÄ±r
- âœ… Web UI eriÅŸilebilir olur

## ðŸ“ž Ek Destek

Hala sorun yaÅŸÄ±yorsanÄ±z:

1. **Build loglarÄ±nÄ± kontrol edin**: `docker-compose build 2>&1 | tee build.log`
2. **GPU driver'Ä± kontrol edin**: `nvidia-smi`
3. **Disk alanÄ±nÄ± kontrol edin**: `df -h`
4. **Docker cache temizleyin**: `docker system prune -af`

---

**Son GÃ¼ncelleme**: 12 KasÄ±m 2025
**CUDA Versiyonu**: 12.1.0
**PyTorch Versiyonu**: 2.4.0
**vLLM Versiyonu**: 0.8.5

