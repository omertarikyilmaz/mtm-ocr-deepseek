"""
MTM Batch OCR Processor
Medya Takip Merkezi iÃ§in birden fazla gazete sayfasÄ±nÄ± batch olarak okuyup 
her kelimenin pozisyonunu kaydeden sistem
"""

import os
import re
import json
import glob
import base64
from typing import List, Dict, Tuple, Optional
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

import torch
if torch.version.cuda == '11.8':
    os.environ["TRITON_PTXAS_PATH"] = "/usr/local/cuda-11.8/bin/ptxas"
os.environ['VLLM_USE_V1'] = '0'

from PIL import Image, ImageDraw, ImageFont
import numpy as np

from vllm import LLM, SamplingParams
from vllm.model_executor.models.registry import ModelRegistry

# Import local modules
from deepseek_vllm.deepseek_ocr import DeepseekOCRForCausalLM
from deepseek_vllm.process.ngram_norepeat import NoRepeatNGramLogitsProcessor
from deepseek_vllm.process.image_process import DeepseekOCRProcessor

ModelRegistry.register_model("DeepseekOCRForCausalLM", DeepseekOCRForCausalLM)


class MTMOCRProcessor:
    """Medya Takip Merkezi iÃ§in OCR iÅŸleyici"""
    
    def __init__(
        self,
        model_path: str = "deepseek-ai/DeepSeek-OCR",
        output_dir: str = "output",
        device: str = "0",
        max_concurrency: int = 50,
        crop_mode: bool = True
    ):
        """
        Args:
            model_path: DeepSeek-OCR model yolu
            output_dir: Ã‡Ä±ktÄ± klasÃ¶rÃ¼
            device: GPU device ID
            max_concurrency: Maksimum eÅŸzamanlÄ± iÅŸlem sayÄ±sÄ±
            crop_mode: Dinamik kÄ±rpma modu
        """
        os.environ["CUDA_VISIBLE_DEVICES"] = device
        
        self.model_path = model_path
        self.output_dir = output_dir
        # Originals klasÃ¶rÃ¼nÃ¼ oluÅŸtur (gÃ¶rselleri saklamak iÃ§in)
        self.originals_dir = os.path.join(output_dir, 'originals')
        os.makedirs(self.originals_dir, exist_ok=True)
        self.crop_mode = crop_mode
        
        # Output dizinlerini oluÅŸtur
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'results'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'visualizations'), exist_ok=True)
        
        print("\n[INFO] DeepSeek OCR modeli yukleniyor")
        print(f"       Model: {model_path}")
        
        import time
        start_time = time.time()
        
        self.llm = LLM(
            model=model_path,
            hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
            block_size=256,
            enforce_eager=False,
            trust_remote_code=True,
            max_model_len=8192,
            swap_space=0,
            max_num_seqs=max_concurrency,
            tensor_parallel_size=1,
            gpu_memory_utilization=0.9,
        )
        
        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=40, 
                window_size=90, 
                whitelist_token_ids={128821, 128822}
            )
        ]
        
        self.sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=8192,
            logits_processors=logits_processors,
            skip_special_tokens=False,
        )
        
        self.processor = DeepseekOCRProcessor()
        
        total_time = time.time() - start_time
        print(f"[INFO] Model yukleme tamamlandi ({total_time:.1f} saniye)")
    
    def extract_word_positions(
        self, 
        text: str, 
        image_width: int, 
        image_height: int
    ) -> List[Dict]:
        """
        OCR Ã§Ä±ktÄ±sÄ±ndan kelimelerin pozisyonlarÄ±nÄ± Ã§Ä±kart
        
        Args:
            text: OCR Ã§Ä±ktÄ± metni
            image_width: GÃ¶rsel geniÅŸliÄŸi
            image_height: GÃ¶rsel yÃ¼ksekliÄŸi
            
        Returns:
            Kelime pozisyon bilgileri listesi
        """
        word_positions = []
        
        # GROUNDING TAG OLMADAN: Modelin kendi formatÄ±nÄ± kontrol et
        # Bazen markdown format dÃ¶ndÃ¼rÃ¼r, bazen dÃ¼z metin
        
        # DEBUG: Free OCR response'un baÅŸÄ±nÄ± gÃ¶ster
        print(f"[DEBUG FREE OCR] Response uzunluÄŸu: {len(text)} karakter")
        print(f"[DEBUG FREE OCR] Ä°lk 500 karakter: {text[:500]}")
        
        # Format 1: <|ref|>text<|/ref|><|det|>coords<|/det|>
        pattern1 = r'<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>'
        matches1 = re.findall(pattern1, text, re.DOTALL)
        
        # Format 2: <|ref|>text<|/ref|><|box|>coords<|/box|>
        pattern2 = r'<\|ref\|>(.*?)<\|/ref\|><\|box\|>(.*?)<\|/box\|>'
        matches2 = re.findall(pattern2, text, re.DOTALL)
        
        # Hangisi daha fazla sonuÃ§ veriyorsa onu kullan
        if len(matches1) > 0:
            matches = matches1
            format_name = "det"
            print(f"[DEBUG FREE OCR] {len(matches1)} adet <|det|> match bulundu")
        elif len(matches2) > 0:
            matches = matches2
            format_name = "box"
            print(f"[DEBUG FREE OCR] {len(matches2)} adet <|box|> match bulundu")
        else:
            matches = []
            format_name = "none"
            print(f"[DEBUG FREE OCR] HiÃ§ bbox match bulunamadÄ±!")
        
        if format_name == "none":
            return []
        
        for idx, (word_text, coordinates_str) in enumerate(matches):
            try:
                # KoordinatlarÄ± parse et (gÃ¼venli)
                import ast
                coordinates = ast.literal_eval(coordinates_str)
                
                # Liste iÃ§inde liste varsa dÃ¼zleÅŸtir
                if isinstance(coordinates, list):
                    if len(coordinates) > 0 and isinstance(coordinates[0], list):
                        # [[x1,y1,x2,y2]] formatÄ±
                        bbox_list = coordinates
                    else:
                        # [x1,y1,x2,y2] formatÄ±
                        bbox_list = [coordinates]
                    
                    for bbox in bbox_list:
                        if len(bbox) >= 4:
                            x1, y1, x2, y2 = bbox[:4]
                            
                            # DEBUG: Ä°lk 3 kelime iÃ§in bbox'larÄ± gÃ¶ster
                            if idx < 3:
                                print(f"[DEBUG FREE OCR] '{word_text}' normalize bbox: {bbox}")
                            
                            # DeepSeek OCR HER ZAMAN 0-999 arasÄ± normalize dÃ¶ndÃ¼rÃ¼r!
                            # Resmi kod: x1 = int(x1 / 999 * image_width)
                            # modeling_deepseekocr.py satÄ±r 104-108
                            pixel_x1 = int(x1 / 999 * image_width)
                            pixel_y1 = int(y1 / 999 * image_height)
                            pixel_x2 = int(x2 / 999 * image_width)
                            pixel_y2 = int(y2 / 999 * image_height)
                            
                            # DEBUG: Ä°lk 3 kelime iÃ§in pixel bbox'larÄ± gÃ¶ster
                            if idx < 3:
                                print(f"[DEBUG FREE OCR] '{word_text}' pixel bbox: x1={pixel_x1}, y1={pixel_y1}, x2={pixel_x2}, y2={pixel_y2}, w={pixel_x2-pixel_x1}, h={pixel_y2-pixel_y1}")
                            
                            word_positions.append({
                                'text': word_text.strip(),
                                'bbox': {
                                    'x1': pixel_x1,
                                    'y1': pixel_y1,
                                    'x2': pixel_x2,
                                    'y2': pixel_y2,
                                    'width': pixel_x2 - pixel_x1,
                                    'height': pixel_y2 - pixel_y1
                                },
                                'normalized_bbox': {
                                    'x1': x1,
                                    'y1': y1,
                                    'x2': x2,
                                    'y2': y2
                                },
                                'index': idx
                            })
            except Exception as e:
                continue
        
        return word_positions
    
    def extract_text_only(self, text: str) -> str:
        """
        OCR Ã§Ä±ktÄ±sÄ±ndan sadece metni Ã§Ä±kart
        """
        pattern = r'<\|ref\|>(.*?)<\|/ref\|>'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if matches:
            clean_text = ' '.join(match.strip() for match in matches if match.strip())
        else:
            clean_text = re.sub(r'<\|.*?\|>', '', text)
            clean_text = re.sub(r'\n\n+', '\n\n', clean_text)
            clean_text = re.sub(r' +', ' ', clean_text)
        
        return clean_text.strip()
    
    def visualize_word_positions(
        self,
        image_path: str,
        word_positions: List[Dict],
        output_path: str,
        show_text: bool = True,
        box_color: tuple = None,
        box_width: int = 2
    ) -> Image.Image:
        """
        JSON'dan alÄ±nan kelime pozisyonlarÄ±nÄ± gÃ¶rsel Ã¼zerinde gÃ¶ster
        DeepSeek'ten baÄŸÄ±msÄ±z, kendi kutu Ã§izme sistemimiz
        
        Args:
            image_path: Orijinal gÃ¶rsel yolu
            word_positions: JSON'dan gelen kelime pozisyonlarÄ±
            output_path: Ã‡Ä±ktÄ± dosya yolu
            show_text: Kutunun Ã¼stÃ¼nde metni gÃ¶ster
            box_color: Kutu rengi (None ise rastgele)
            box_width: Kutu Ã§izgi kalÄ±nlÄ±ÄŸÄ±
            
        Returns:
            Bounding box'lÄ± gÃ¶rsel
        """
        image = Image.open(image_path).convert('RGB')
        img_draw = image.copy()
        draw = ImageDraw.Draw(img_draw, 'RGBA')
        
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 12)
        except:
            font = ImageFont.load_default()
        
        for idx, word_info in enumerate(word_positions):
            try:
                bbox = word_info['bbox']
                text = word_info.get('text', '')
                
                if box_color:
                    color = box_color
                else:
                    hue = (idx * 137.5) % 360
                    import colorsys
                    rgb = colorsys.hsv_to_rgb(hue/360, 0.7, 0.9)
                    color = tuple(int(c * 255) for c in rgb)
                
                x1, y1 = bbox['x1'], bbox['y1']
                x2, y2 = bbox['x2'], bbox['y2']
                draw.rectangle([x1, y1, x2, y2], outline=color, width=box_width)
                
            except Exception as e:
                continue
        
        img_draw.save(output_path, quality=95)
        return img_draw
    
    def process_single_image(
        self,
        image_path: str,
        prompt: str = "<image>\n<|grounding|>\nFree OCR.",
        use_word_location: bool = True
    ) -> Dict:
        """
        Tek bir gÃ¶rseli iÅŸle
        
        Args:
            image_path: GÃ¶rsel dosya yolu
            prompt: OCR prompt
            
        Returns:
            Ä°ÅŸlem sonucu bilgileri
        """
        try:
            image = Image.open(image_path).convert('RGB')
            image_width, image_height = image.size
            
            # Image processing
            cache_item = {
                "prompt": prompt,
                "multi_modal_data": {
                    "image": self.processor.tokenize_with_images(
                        images=[image],
                        bos=True,
                        eos=True,
                        cropping=self.crop_mode
                    )
                },
            }
            
            return {
                'cache_item': cache_item,
                'image': image,
                'image_path': image_path,
                'width': image_width,
                'height': image_height
            }
            
        except Exception as e:
            print(f"[HATA] Gorsel isleme hatasi: {image_path}")
            return None
    
    def locate_words_in_image(
        self,
        image_path: str,
        words: List[str],
        batch_size: int = 10
    ) -> Dict[str, Dict]:
        """
        Her kelime iÃ§in Locate (REC) mode ile koordinat bul
        Prompt: <image>\nLocate <|ref|>xxxx<|/ref|> in the image.
        
        Bu mod Free OCR'dan DAHA DOÄžRU pozisyon verir!
        """
        word_locations = {}
        image = Image.open(image_path).convert('RGB')
        image_width, image_height = image.size
        
        print(f"[LOCATE] {len(words)} kelime iÃ§in pozisyon bulunuyor...")
        
        for i in range(0, len(words), batch_size):
            batch_words = words[i:i+batch_size]
            
            for word in batch_words:
                try:
                    # âœ… FIX: <|grounding|> tag'ini ekle (yardÄ±mcÄ± kaynaktan)
                    locate_prompt = f"<image>\n<|grounding|>\nLocate <|ref|>{word}<|/ref|> in the image."
                    
                    cache_item = {
                        "prompt": locate_prompt,
                        "multi_modal_data": {
                            "image": self.processor.tokenize_with_images(
                                images=[image],
                                bos=True,
                                eos=True,
                                cropping=self.crop_mode
                            )
                        },
                    }
                    
                    output = self.llm.generate([cache_item], sampling_params=self.sampling_params)[0]
                    response = output.outputs[0].text
                    
                    # DEBUG: Ä°lk 3 kelime iÃ§in response'u gÃ¶ster
                    if len(word_locations) < 3:
                        print(f"[DEBUG] '{word}' iÃ§in DeepSeek response: {response[:300]}...")
                    
                    # âœ… FIX: DoÄŸru regex pattern (ref ve det tag'lerini birlikte yakala)
                    # Pattern: <|ref|>kelime<|/ref|><|det|>[[coords]]<|/det|>
                    pattern = r'<\|ref\|>(?P<label>.*?)<\|/ref\|>\s*<\|det\|>\s*(?P<coords>\[.*?\])\s*<\|/det\|>'
                    coords_match = re.search(pattern, response, re.DOTALL)
                    
                    if coords_match:
                        coords_str = coords_match.group('coords').strip()
                        
                        # DEBUG: Raw coords string
                        if len(word_locations) < 3:
                            print(f"[DEBUG] '{word}' raw coords: {coords_str}")
                        
                        # âœ… FIX: ast.literal_eval kullan (daha gÃ¼venli)
                        import ast
                        parsed = ast.literal_eval(coords_str)
                        
                        # âœ… FIX: Ã‡oklu bbox desteÄŸi (yardÄ±mcÄ± kaynaktan)
                        # Tek bbox: [x1,y1,x2,y2] veya [[x1,y1,x2,y2]]
                        # Ã‡oklu bbox: [[x1,y1,x2,y2], [x1,y1,x2,y2], ...]
                        if isinstance(parsed, list) and len(parsed) == 4 and all(isinstance(n, (int, float)) for n in parsed):
                            # Tek bbox: [x1,y1,x2,y2]
                            box_coords = [parsed]
                            if len(word_locations) < 3:
                                print(f"[DEBUG] '{word}' tek bbox tespit edildi")
                        elif isinstance(parsed, list):
                            # Ã‡oklu bbox veya [[x1,y1,x2,y2]]
                            box_coords = parsed
                            if len(word_locations) < 3:
                                print(f"[DEBUG] '{word}' {len(box_coords)} bbox tespit edildi")
                        else:
                            print(f"[UYARI] '{word}' iÃ§in beklenmeyen format: {type(parsed)}")
                            continue
                        
                        # Her bbox iÃ§in iÅŸle (aynÄ± kelime birden fazla yerde olabilir!)
                        word_lower = word.lower()
                        word_locations[word_lower] = []  # Liste olarak sakla
                        
                        for idx, bbox in enumerate(box_coords):
                            if isinstance(bbox, (list, tuple)) and len(bbox) >= 4:
                                # DEBUG
                                if len(word_locations) < 3:
                                    print(f"[DEBUG] '{word}' bbox {idx+1}: normalize {bbox}")
                                    print(f"[DEBUG] GÃ¶rsel boyutu: {image_width}x{image_height}")
                                
                                # Normalize (0-999) â†’ Pixel
                                x1 = int(float(bbox[0]) / 999 * image_width)
                                y1 = int(float(bbox[1]) / 999 * image_height)
                                x2 = int(float(bbox[2]) / 999 * image_width)
                                y2 = int(float(bbox[3]) / 999 * image_height)
                                
                                # DEBUG
                                if len(word_locations) < 3:
                                    print(f"[DEBUG] '{word}' bbox {idx+1}: pixel x1={x1}, y1={y1}, x2={x2}, y2={y2}, w={x2-x1}, h={y2-y1}")
                                
                                word_locations[word_lower].append({
                                    'bbox': {
                                        'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2,
                                        'width': x2 - x1, 'height': y2 - y1
                                    }
                                })
                        
                        if len(word_locations) % 10 == 0:
                            print(f"[LOCATE] {len(word_locations)}/{len(words)} kelime bulundu")
                                    
                except Exception as e:
                    print(f"[LOCATE] Hata '{word}': {e}")
                    continue
        
        print(f"[LOCATE] Toplam {len(word_locations)} kelime pozisyonu bulundu")
        return word_locations
    
    def process_batch(
        self,
        image_paths: List[str],
        prompt: str = "<image>\n<|grounding|>\nFree OCR.",
        num_workers: int = 32,
        progress_callback: Optional[callable] = None,
        use_word_location: bool = False  # Free OCR bbox'larÄ±nÄ± kullan
    ) -> List[Dict]:
        """
        Birden fazla gÃ¶rseli batch olarak iÅŸle
        
        Args:
            image_paths: GÃ¶rsel dosya yollarÄ± listesi
            prompt: OCR prompt
            num_workers: Paralel iÅŸlem sayÄ±sÄ±
            progress_callback: Progress gÃ¼ncellemesi iÃ§in callback fonksiyonu
            
        Returns:
            TÃ¼m gÃ¶rseller iÃ§in OCR sonuÃ§larÄ±
        """
        print(f"\n[INFO] {len(image_paths)} gazete sayfasi isleniyor...")
        
        if progress_callback:
            progress_callback(0, len(image_paths), "Gorseller hazirlaniyor")
        
        # GÃ¶rselleri paralel olarak hazÄ±rla
        print("[1/3] Gorseller hazirlaniyor...")
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            processed_images = list(
                executor.map(
                    lambda p: self.process_single_image(p, prompt),
                    image_paths
                )
            )
        
        # None deÄŸerleri filtrele
        processed_images = [img for img in processed_images if img is not None]
        
        if not processed_images:
            print("[HATA] Islenecek gorsel bulunamadi")
            return []
        if progress_callback:
            progress_callback(0, len(processed_images), "OCR islemi yapiliyor")
            
        batch_inputs = [img['cache_item'] for img in processed_images]
        
        outputs_list = self.llm.generate(
            batch_inputs,
            sampling_params=self.sampling_params
        )
        
        if progress_callback:
            progress_callback(0, len(processed_images), "Sonuclar kaydediliyor")
            
        results = []
        
        for idx, (output, img_data) in enumerate(zip(outputs_list, processed_images)):
            if progress_callback:
                progress_callback(idx + 1, len(processed_images), f"Sonuc kaydediliyor ({idx+1}/{len(processed_images)})")
            try:
                # OCR Ã§Ä±ktÄ±sÄ±
                ocr_text = output.outputs[0].text
                
                # Dosya adÄ± (benzersiz ID'den)
                image_path_obj = Path(img_data['image_path'])
                image_filename = image_path_obj.name  # {unique_id}.jpg formatÄ±nda
                image_id = image_path_obj.stem  # Benzersiz ID (uzantÄ±sÄ±z)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # YÃ¼klenen gÃ¶rsel yolu (uploads klasÃ¶rÃ¼ndeki orijinal)
                original_upload_path = img_data['image_path']
                
                # Kelime pozisyonlarÄ±nÄ± Ã§Ä±kart
                word_positions = self.extract_word_positions(
                    ocr_text,
                    img_data['width'],
                    img_data['height']
                )
                
                # Temiz metni Ã§Ä±kart
                clean_text = self.extract_text_only(ocr_text)
                
                # GÃ¶rseli base64 olarak oku - YUKLENEN GORSELI DIREKT AL
                image_base64 = None
                try:
                    # YÃ¼klenen gÃ¶rseli direkt al (img_data['image_path'] = uploads/{unique_id}.jpg)
                    upload_image_path = img_data['image_path']
                    if os.path.exists(upload_image_path):
                        with open(upload_image_path, 'rb') as img_file:
                            image_data = img_file.read()
                            image_base64 = base64.b64encode(image_data).decode('utf-8')
                            print(f"[INFO] Gorsel base64'e cevrildi: {upload_image_path}")
                    else:
                        print(f"[HATA] Gorsel bulunamadi: {upload_image_path}")
                except Exception as e:
                    print(f"[HATA] Gorsel base64'e cevrilemedi: {e}")
                    import traceback
                    print(traceback.format_exc())
                
                # Free OCR genelde pozisyonlarÄ± eksik verir
                # Her kelime iÃ§in Locate (REC) mode kullan - DAHA DOÄžRU
                print(f"[INFO] Free OCR'dan {len(word_positions)} kelime pozisyonu bulundu")
                
                if use_word_location:
                    # TÃ¼m kelimeleri Ã§Ä±kar
                    all_words = clean_text.split()
                    all_words = [w.strip('.,!?;:()[]{}\"\'') for w in all_words if len(w.strip('.,!?;:()[]{}\"\'')) > 0]
                    
                    # Unique kelimeleri bul
                    seen = set()
                    unique_words = []
                    for word in all_words:
                        word_lower = word.lower()
                        if word_lower not in seen and len(word) > 1:  # Tek harfleri atla
                            seen.add(word_lower)
                            unique_words.append(word)
                    
                    print(f"[INFO] Locate mode ile {len(unique_words)} unique kelime aranacak...")
                    
                    # Her kelime iÃ§in Locate mode ile pozisyon bul
                    word_locations = self.locate_words_in_image(
                        img_data['image_path'], 
                        unique_words, 
                        batch_size=10  # Daha kÃ¼Ã§Ã¼k batch
                    )
                    
                    print(f"[INFO] Locate mode'dan {len(word_locations)} kelime pozisyonu bulundu")
                    
                    # DEBUG: Ä°lk 3 kelimenin bbox'larÄ±nÄ± gÃ¶ster
                    if word_locations:
                        print(f"[DEBUG] Ä°lk 3 kelime lokasyonu:")
                        for word, bbox_list in list(word_locations.items())[:3]:
                            print(f"  '{word}': {len(bbox_list)} bbox bulundu")
                            for i, bbox_data in enumerate(bbox_list[:2]):  # Ä°lk 2 bbox'Ä± gÃ¶ster
                                print(f"    [{i+1}] {bbox_data['bbox']}")
                    else:
                        print(f"[UYARI] Locate mode hiÃ§ kelime bulamadÄ±! Free OCR bbox'larÄ± kullanÄ±lacak.")
                    
                    # âœ… FIX: Ã‡oklu bbox desteÄŸi - her kelime tekrarÄ± iÃ§in sÄ±radaki bbox'Ä± kullan
                    word_positions = []
                    bbox_usage_count = {}  # Her kelime iÃ§in kaÃ§ bbox kullandÄ±ÄŸÄ±mÄ±zÄ± takip et
                    
                    for idx, word_text in enumerate(all_words):
                        word_lower = word_text.lower()
                        if word_lower in word_locations:
                            # Bu kelimenin kaÃ§Ä±ncÄ± tekrarÄ±?
                            used_count = bbox_usage_count.get(word_lower, 0)
                            bbox_list = word_locations[word_lower]
                            
                            # EÄŸer bu tekrar iÃ§in bbox varsa kullan
                            if used_count < len(bbox_list):
                                word_positions.append({
                                    'text': word_text,
                                    'bbox': bbox_list[used_count]['bbox'],
                                    'index': idx,
                                    'occurrence': used_count + 1  # KaÃ§Ä±ncÄ± tekrar olduÄŸunu belirt
                                })
                                bbox_usage_count[word_lower] = used_count + 1
                            else:
                                # Bbox kalmadÄ±, bu tekrarÄ± atla veya uyarÄ± ver
                                if used_count == len(bbox_list):  # Ä°lk kez bbox bittiÄŸinde uyar
                                    print(f"[UYARI] '{word_text}' iÃ§in {len(bbox_list)} bbox var ama {used_count+1}. tekrar isteniyor")
                                bbox_usage_count[word_lower] = used_count + 1
                
                # JSON sonuÃ§
                result_data = {
                    'image_id': image_id,
                    'image_filename': image_filename,
                    'image_path': original_upload_path,
                    'timestamp': timestamp,
                    'image_size': {
                        'width': img_data['width'],
                        'height': img_data['height']
                    },
                    'word_count': len(word_positions),
                    'words': word_positions,
                    'full_text': clean_text,
                    'raw_ocr_output': ocr_text,
                    'image_base64': image_base64
                }
                
                # Base64 kontrolÃ¼
                if image_base64 is None:
                    print(f"[HATA] image_base64 None! Gorsel: {original_upload_path}")
                else:
                    print(f"[INFO] image_base64 hazir, uzunluk: {len(image_base64)} karakter")
                
                # JSON dosyasÄ±nÄ± kaydet - DOSYA ADI = image_id.json (basit ve garantili)
                json_filename = f'{image_id}.json'
                json_path = os.path.join(
                    self.output_dir,
                    'results',
                    json_filename
                )
                print(f"[INFO] JSON kaydediliyor: {json_path}")
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, ensure_ascii=False, indent=2)
                
                # TXT dosyasÄ± artÄ±k kaydedilmiyor - her ÅŸey JSON'da
                
                # GÃ¶rselleÅŸtirme YOK - KullanÄ±cÄ± manuel seÃ§ecek
                # viz_path = os.path.join(
                #     self.output_dir,
                #     'visualizations',
                #     f'{image_filename}_{timestamp}_boxes.jpg'
                # )
                # self.visualize_word_positions(
                #     img_data['image_path'],  # Orijinal gÃ¶rsel yolu
                #     word_positions,
                #     viz_path,
                #     show_text=True,  # Kelimeyi gÃ¶ster
                #     box_width=2  # Ä°nce Ã§izgi
                # )
                
                results.append(result_data)
                
                print(f"[INFO] {image_filename}: {len(word_positions)} kelime islendi")
                
            except Exception as e:
                print(f"[HATA] Sonuc kaydetme hatasi: {img_data['image_path']}")
                continue
        
        print(f"\n[INFO] Islem tamamlandi: {len(results)} dosya islendi")
        print(f"       Sonuclar: {self.output_dir}/results/")
        
        return results


def main():
    """Ana fonksiyon - CLI kullanÄ±mÄ± iÃ§in"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='MTM Batch OCR - Gazete sayfalarÄ±nÄ± toplu olarak OCR ile iÅŸle'
    )
    parser.add_argument(
        '--input',
        type=str,
        required=True,
        help='Girdi klasÃ¶rÃ¼ veya dosya pattern (Ã¶rn: ./gazeteler/*.jpg)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='./output',
        help='Ã‡Ä±ktÄ± klasÃ¶rÃ¼'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='deepseek-ai/DeepSeek-OCR',
        help='Model yolu'
    )
    parser.add_argument(
        '--device',
        type=str,
        default='0',
        help='GPU device ID'
    )
    parser.add_argument(
        '--concurrency',
        type=int,
        default=50,
        help='Maksimum eÅŸzamanlÄ± iÅŸlem sayÄ±sÄ±'
    )
    parser.add_argument(
        '--workers',
        type=int,
        default=32,
        help='Paralel iÅŸlem sayÄ±sÄ±'
    )
    parser.add_argument(
        '--no-crop',
        action='store_true',
        help='Dinamik kÄ±rpma modunu devre dÄ±ÅŸÄ± bÄ±rak'
    )
    
    args = parser.parse_args()
    
    # GÃ¶rsel dosyalarÄ±nÄ± bul
    if os.path.isdir(args.input):
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
        image_paths = []
        for ext in image_extensions:
            image_paths.extend(glob.glob(os.path.join(args.input, ext)))
    else:
        image_paths = glob.glob(args.input)
    
    if not image_paths:
        print(f"[HATA] {args.input} konumunda gorsel bulunamadi")
        return
    
    print(f"[INFO] {len(image_paths)} gorsel bulundu")
    
    # Processor'Ä± baÅŸlat
    processor = MTMOCRProcessor(
        model_path=args.model,
        output_dir=args.output,
        device=args.device,
        max_concurrency=args.concurrency,
        crop_mode=not args.no_crop
    )
    
    # Batch iÅŸleme
    results = processor.process_batch(
        image_paths,
        num_workers=args.workers
    )
    
    # Ã–zet rapor
    if results:
        total_words = sum(r['word_count'] for r in results)
        print(f"\nðŸ“Š Ã–ZET RAPOR:")
        print(f"   - Ä°ÅŸlenen sayfa: {len(results)}")
        print(f"   - Toplam kelime: {total_words}")
        print(f"   - Ortalama kelime/sayfa: {total_words/len(results):.1f}")


if __name__ == "__main__":
    main()

